import streamlit as st
import logging
from openai import OpenAI

# é¡¹ç›®æ¨¡å—å¯¼å…¥
# ===================== ä¿®æ”¹ç‚¹åœ¨è¿™é‡Œ =====================
# æˆ‘ä»¬å°†å¯¼å…¥æ•´ä¸ª config æ¨¡å—ï¼Œè€Œä¸æ˜¯åªå¯¼å…¥é‡Œé¢çš„å˜é‡
import config 
# =======================================================
from vectordb_manager import VectorDBManager
from cache import QueryCache
from workflow import MyopiaControlWorkflow

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Evidence-Based AI for Myopia Control",
    page_icon="ğŸ”¬",
    layout="wide"
)

# --- UI æ–‡æœ¬å¤šè¯­è¨€æ”¯æŒ ---
UI_TEXTS = {
    "en": {
        "title": "ğŸ”¬ Evidence-Based Conversational AI for Low-Concentration Atropine in Myopia Control",
        "subtitle": "An AI assistant providing evidence-based answers from medical literature.",
        "input_label": "Ask a question about low-concentration atropine for myopia:",
        "input_placeholder": "e.g., What is the efficacy of 0.01% atropine compared to 0.05%?",
        "spinner_text": "Analyzing medical literature... ğŸ’¡",
        "answer_header": "ğŸ’¬ Answer",
        "context_header": "View Evidence Source",
        "context_subheader": "The following excerpts from the literature were used to generate the answer:",
        "error_init": "System initialization failed. Please check logs and configuration.",
        "error_runtime": "An unexpected error occurred during processing.",
        "footer": "â¤ï¸ **Disclaimer:** This AI assistant provides information from medical literature for research and reference purposes only. It is not a substitute for professional medical advice, diagnosis, or treatment. Always consult a qualified healthcare provider for any medical concerns."
    },
    "zh": {
        "title": "ğŸ”¬ ä½æµ“åº¦é˜¿æ‰˜å“è¿‘è§†æ§åˆ¶çš„å¾ªè¯å¯¹è¯å¼AI",
        "subtitle": "ä¸€ä¸ªåŸºäºåŒ»å­¦æ–‡çŒ®ï¼Œæä¾›å¾ªè¯ç­”æ¡ˆçš„AIåŠ©æ‰‹ã€‚",
        "input_label": "è¯·è¾“å…¥å…³äºä½æµ“åº¦é˜¿æ‰˜å“åœ¨è¿‘è§†æ§åˆ¶æ–¹é¢çš„é—®é¢˜ï¼š",
        "input_placeholder": "ä¾‹å¦‚ï¼š0.01%é˜¿æ‰˜å“ä¸0.05%é˜¿æ‰˜å“ç›¸æ¯”ï¼Œç–—æ•ˆå¦‚ä½•ï¼Ÿ",
        "spinner_text": "æ­£åœ¨åˆ†æåŒ»å­¦æ–‡çŒ®... ğŸ’¡",
        "answer_header": "ğŸ’¬ å›ç­”",
        "context_header": "æŸ¥çœ‹è¯æ®æ¥æº",
        "context_subheader": "ä»¥ä¸‹æ˜¯ç”¨äºç”Ÿæˆç­”æ¡ˆçš„æ–‡çŒ®åŸæ–‡ç‰‡æ®µï¼š",
        "error_init": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å’Œé…ç½®ã€‚",
        "error_runtime": "å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚",
        "footer": "â¤ï¸ **é‡è¦å£°æ˜:** æœ¬AIåŠ©æ‰‹æä¾›çš„ä¿¡æ¯æ¥æºäºåŒ»å­¦æ–‡çŒ®ï¼Œä»…ä¾›ç§‘ç ”ä¸å‚è€ƒã€‚å®ƒä¸èƒ½æ›¿ä»£ä¸“ä¸šçš„åŒ»ç–—å»ºè®®ã€è¯Šæ–­æˆ–æ²»ç–—ã€‚å¦‚æœ‰ä»»ä½•åŒ»ç–—é—®é¢˜ï¼Œè¯·åŠ¡å¿…å’¨è¯¢åˆæ ¼çš„åŒ»ç–—ä¸“ä¸šäººå‘˜ã€‚"
    }
}

# --- ç»„ä»¶åˆå§‹åŒ– (ä½¿ç”¨Streamlitç¼“å­˜) ---
@st.cache_resource
def initialize_components():
    """åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿæ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ã€‚"""
    logger.info("æ­£åœ¨åˆå§‹åŒ–ç»„ä»¶...")
    try:
        # 1. LLM å®¢æˆ·ç«¯
        if not config.DASHSCOPE_API_KEY:
            st.error("é”™è¯¯ï¼šè¯·åœ¨Streamlit Cloudçš„Secretsä¸­è®¾ç½® DASHSCOPE_API_KEYã€‚")
            return None
        llm_client = OpenAI(api_key=config.DASHSCOPE_API_KEY, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")

        # 2. å‘é‡æ•°æ®åº“ç®¡ç†å™¨
        vdb_manager = VectorDBManager()
        vdb_manager.load_db()

        # 3. æŸ¥è¯¢ç¼“å­˜ (å¯é€‰)
        cache = QueryCache(host=config.REDIS_HOST, port=config.REDIS_PORT, db=config.REDIS_DB)
        if not cache.redis_client:
            st.warning("æ— æ³•è¿æ¥åˆ°Redisï¼Œç¼“å­˜åŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚")
            cache = None

        # 4. åˆå§‹åŒ–å·¥ä½œæµ
        workflow = MyopiaControlWorkflow(
            llm_client=llm_client,
            retriever=vdb_manager,
            cache=cache
        )
        logger.info("æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–æˆåŠŸã€‚")
        return workflow

    except Exception as e:
        st.error(f"ç»„ä»¶åˆå§‹åŒ–æœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        logger.exception("Streamlitåº”ç”¨ç»„ä»¶åˆå§‹åŒ–æœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯ã€‚")
        return None

# --- ä¸»åº”ç”¨é€»è¾‘ ---
if 'lang' not in st.session_state:
    st.session_state['lang'] = 'en'

def set_language():
    st.session_state['lang'] = st.session_state['lang_selector']

st.sidebar.radio(
    label="Language / è¯­è¨€",
    options=['en', 'zh'],
    format_func=lambda x: "English" if x == 'en' else "ä¸­æ–‡",
    key='lang_selector',
    on_change=set_language
)
texts = UI_TEXTS[st.session_state.lang]

st.title(texts["title"])
st.markdown(f"##### {texts['subtitle']}")
st.markdown("---")

workflow_instance = initialize_components()

if workflow_instance:
    user_question = st.text_input(
        texts["input_label"],
        placeholder=texts["input_placeholder"]
    )

    if user_question:
        with st.spinner(texts["spinner_text"]):
            try:
                result = workflow_instance.run(user_question, language=st.session_state.lang)

                st.markdown("---")
                st.subheader(texts["answer_header"])
                st.markdown(result.get("answer", "No answer generated."))

                with st.expander(texts["context_header"]):
                    st.markdown(f"**{texts['context_subheader']}**")
                    st.text(result.get("formatted_context", "No context available."))

                if result.get("error"):
                    st.error(f"An error occurred: {result.get('error')}")

            except Exception as e:
                st.error(f"{texts['error_runtime']}: {str(e)}")
                logger.exception(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™ '{user_question}':")
else:
    st.error(UI_TEXTS["en"]["error_init"])

st.markdown("---")
st.markdown(texts["footer"])